{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel Processing - Example\n",
        "\n",
        "Shift contents of an array to the left by one element."
      ],
      "metadata": {
        "id": "6A47HC3gAFeq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF4Rax5OADMD",
        "outputId": "c7df3c70-79ea-41c9-e64d-2e9633622748"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-7rrsso69\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-7rrsso69\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 0a71d56e5dce3ff1f0dd2c47c29367629262f527\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJMBSABgAZFu",
        "outputId": "360465f6-3a4c-4771-833d-6b1063c2bc63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <fcntl.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// our kernel function that takes the array and the size of array as arguments\n",
        "__global__ void kernel(int* a, int *n){\n",
        "\n",
        "    // get the value of i for each thread\n",
        "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    // ensure the value of i is less than the size of the array\n",
        "    if(i < *n){\n",
        "        int temp = a[i+1];\n",
        "        __syncthreads;\n",
        "        a[i] = temp;\n",
        "        __syncthreads;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    int *h_arr; // host array\n",
        "    int *d_arr; // device array\n",
        "    int n = 5;  // size of array\n",
        "    int *d_n;   // size of array (send to device)\n",
        "\n",
        "    // allocate host memory for the array\n",
        "    h_arr = (int*)malloc(n * sizeof(int));\n",
        "\n",
        "    // initialize the array\n",
        "    for(int i = 0; i < n; i++){\n",
        "        h_arr[i] = i;\n",
        "    }\n",
        "\n",
        "    // print the elements of the array\n",
        "    printf(\"Array Elements: \\n\");\n",
        "    for(int i = 0; i < n; i++){\n",
        "        printf(\"%d \", h_arr[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // initialize the size of the block and grid for the kernel\n",
        "    dim3 grid_size(1,1);\n",
        "    dim3 block_size(n);\n",
        "\n",
        "    // allocate device memory for the array and its size variable\n",
        "    cudaMalloc((void**)&d_arr, n * sizeof(int));\n",
        "    cudaMalloc((void**)&d_n, sizeof(int));\n",
        "\n",
        "    // copy the host variable onto the device variables\n",
        "    cudaMemcpy(d_arr, h_arr, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_n, &n, sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // run the kernel function\n",
        "    kernel<<<grid_size, block_size>>>(d_arr, d_n);\n",
        "\n",
        "    // save the new device array by replacing the host array\n",
        "    cudaMemcpy(h_arr, d_arr, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // print the contents of the new array\n",
        "    printf(\"Array Elements After Kernel Function: \\n\");\n",
        "    for(int i = 0; i < n; i++){\n",
        "        printf(\"%d \", h_arr[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    // free host memory\n",
        "    free(h_arr);\n",
        "\n",
        "    // free device memory\n",
        "    cudaFree(d_arr);\n",
        "    cudaFree(d_n);\n",
        "\n",
        "\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRrMhYPjAa5b",
        "outputId": "0a4244e0-bcb8-4579-9ce0-1f85f11726cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Array Elements: \n",
            "0 1 2 3 4 \n",
            "Array Elements After Kernel Function: \n",
            "1 2 3 4 0 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2iy_rcFFA-Hr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}